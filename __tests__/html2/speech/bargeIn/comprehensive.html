<!doctype html>
<html lang="en-US">
  <head>
    <link href="/assets/index.css" rel="stylesheet" type="text/css" />
    <script crossorigin="anonymous" src="/test-harness.js"></script>
    <script crossorigin="anonymous" src="/test-page-object.js"></script>
    <script crossorigin="anonymous" src="/__dist__/webchat-es5.js"></script>
  </head>
  <body>
    <main id="webchat"></main>
    <script type="module">
      import {
        SpeechGrammarList,
        SpeechRecognition,
        SpeechRecognitionAlternative,
        SpeechRecognitionEvent,
        SpeechRecognitionResult,
        SpeechRecognitionResultList
      } from 'https://unpkg.com/react-dictate-button@main/dist/react-dictate-button.internal.mjs';
      import { fn, spyOn } from 'https://esm.sh/jest-mock';
      import { SpeechSynthesis, SpeechSynthesisEvent, SpeechSynthesisUtterance } from '../js/index.js';
      import { waitFor } from 'https://unpkg.com/@testduet/wait-for@main/dist/wait-for.mjs';

      const {
        testHelpers: { createDirectLineEmulator },
        WebChat: { renderWebChat }
      } = window;

      run(async function () {
        const speechSynthesis = new SpeechSynthesis();
        const ponyfill = {
          SpeechGrammarList,
          SpeechRecognition: fn().mockImplementationOnce(() => {
            const speechRecognition = new SpeechRecognition();

            speechRecognitionStart = spyOn(speechRecognition, 'start');

            return speechRecognition;
          }),
          speechSynthesis,
          SpeechSynthesisUtterance
        };
        let speechRecognitionStart;

        const speechSynthesisSpeak = spyOn(speechSynthesis, 'speak');

        const { directLine, store } = createDirectLineEmulator();

        renderWebChat(
          {
            directLine,
            store,
            webSpeechPonyfillFactory: () => ponyfill
          },
          document.getElementById('webchat')
        );

        await pageConditions.uiConnected();

        const { resolveAll } = await directLine.actPostActivity(async () => {
          await pageObjects.clickMicrophoneButton();

          expect(speechRecognitionStart).toHaveBeenCalledTimes(1);

          const [{ value: speechRecognition }] = ponyfill.SpeechRecognition.mock.results;

          speechRecognition.dispatchEvent(new Event('start'));
          speechRecognition.dispatchEvent(new Event('audiostart'));
          speechRecognition.dispatchEvent(new Event('soundstart'));
          speechRecognition.dispatchEvent(new Event('speechstart'));
          speechRecognition.dispatchEvent(
            new SpeechRecognitionEvent('result', {
              results: new SpeechRecognitionResultList(
                new SpeechRecognitionResult(new SpeechRecognitionAlternative(0, 'Hello'))
              )
            })
          );

          const [interims] = document.getElementsByClassName('webchat__send-box__dictation-interims');

          // THEN: Interims should be "Hello".
          await waitFor(() => expect(interims.textContent.trimEnd()).toBe('Hello'));

          speechRecognition.dispatchEvent(
            new SpeechRecognitionEvent('result', {
              results: new SpeechRecognitionResultList(
                new SpeechRecognitionResult(new SpeechRecognitionAlternative(0, 'Hello, World!'))
              )
            })
          );

          // THEN: Interims should be "Hello, World!".
          await waitFor(() => expect(interims.textContent.trimEnd()).toBe('Hello, World!'));

          speechRecognition.dispatchEvent(
            new SpeechRecognitionEvent('result', {
              results: new SpeechRecognitionResultList(
                SpeechRecognitionResult.fromFinalized(new SpeechRecognitionAlternative(0.9, 'Hello, World!'))
              )
            })
          );

          speechRecognition.dispatchEvent(new Event('speechend'));
          speechRecognition.dispatchEvent(new Event('soundend'));
          speechRecognition.dispatchEvent(new Event('audioend'));
          speechRecognition.dispatchEvent(new Event('end'));
        });

        await resolveAll();

        // THEN: Should have send the activity.
        await pageConditions.numActivitiesShown(1);

        await directLine.emulateIncomingActivity({
          inputHint: 'expectingInput',
          text: 'Aloha!',
          type: 'message'
        });

        // THEN: Should send a message and the reply from the bot.
        await pageConditions.numActivitiesShown(2);

        // Unsure why speak() is being called twice.
        await waitFor(() => expect(speechSynthesisSpeak).toHaveBeenCalledTimes(2));

        expect(speechSynthesisSpeak).toHaveBeenLastCalledWith(expect.any(SpeechSynthesisUtterance));
        expect(speechSynthesisSpeak).toHaveBeenLastCalledWith(
          expect.objectContaining({
            text: 'Aloha!'
          })
        );

        speechSynthesisSpeak.mock.calls[0][0].dispatchEvent(
          new SpeechSynthesisEvent('end', { utterance: speechSynthesisSpeak.mock.calls[0] })
        );

        speechSynthesisSpeak.mock.calls[1][0].dispatchEvent(
          new SpeechSynthesisEvent('end', { utterance: speechSynthesisSpeak.mock.calls[1] })
        );

        expect(speechSynthesis).toHaveProperty('speaking', false);

        await waitFor(() => expect(speechRecognitionStart).toHaveBeenCalledTimes(2));
      });
    </script>
  </body>
</html>
